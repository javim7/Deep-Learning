{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning\n",
    "#### Laboratorio 6: Sistemas de Recomendaciones\n",
    "##### Sistema de recomendaciones basado en filtros colectivos\n",
    "##### Autores: \n",
    "- Roberto Rios 20979\n",
    "- Javier Mombiela 20067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjmom\\AppData\\Local\\Temp\\ipykernel_107016\\147254837.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('datasets/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv('datasets/Books.csv')\n",
    "users = pd.read_csv('datasets/Users.csv')\n",
    "ratings = pd.read_csv('datasets/Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['ISBN'] = books['ISBN'].astype(str)\n",
    "ratings['ISBN'] = ratings['ISBN'].astype(str)\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "users['User-ID'] = user_enc.fit_transform(users['User-ID'].values)\n",
    "n_users = users['User-ID'].nunique()\n",
    "\n",
    "item_enc = LabelEncoder()\n",
    "item_enc.fit(pd.concat([books['ISBN'], ratings['ISBN']]))\n",
    "books['ISBN'] = item_enc.transform(books['ISBN'])\n",
    "ratings['ISBN'] = item_enc.transform(ratings['ISBN'])\n",
    "n_books = len(item_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-ID encodings:\n",
      "[     0      1      2 ... 278855 278856 278857]\n",
      "ISBN encodings:\n",
      "[ 32170    231  10531 ...   5601  30800 192622]\n"
     ]
    }
   ],
   "source": [
    "print(\"User-ID encodings:\")\n",
    "print(users['User-ID'].unique())\n",
    "\n",
    "print(\"ISBN encodings:\")\n",
    "print(books['ISBN'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos las caracteristicas y el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings[['User-ID', 'ISBN']].values\n",
    "y = ratings['Book-Rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1])\n",
    "user_embedding = Embedding(n_users, 5)(user_input)\n",
    "user_vec = Flatten()(user_embedding)\n",
    "\n",
    "book_input = Input(shape=[1])\n",
    "book_embedding = Embedding(n_books, 5)(book_input)\n",
    "book_vec = Flatten()(book_embedding)\n",
    "\n",
    "concat = Concatenate()([user_vec, book_vec])\n",
    "dense1 = Dense(128, activation='relu')(concat)\n",
    "dense2 = Dense(32, activation='relu')(dense1)\n",
    "output = Dense(1)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 1, 5)                 1394290   ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 1, 5)                 1708825   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 5)                    0         ['embedding_4[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 5)                    0         ['embedding_5[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 10)                   0         ['flatten_4[0][0]',           \n",
      " )                                                                   'flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 128)                  1408      ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 32)                   4128      ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1)                    33        ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3108684 (11.86 MB)\n",
      "Trainable params: 3108684 (11.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([user_input, book_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16169/16169 [==============================] - 838s 52ms/step - loss: 11.6671 - val_loss: 11.2131\n",
      "Epoch 2/3\n",
      "16169/16169 [==============================] - 635s 39ms/step - loss: 9.5744 - val_loss: 12.1073\n",
      "Epoch 3/3\n",
      "16169/16169 [==============================] - 539s 33ms/step - loss: 8.3645 - val_loss: 12.4315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1962831f490>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train[:,0], X_train[:,1]], y_train, batch_size=64, epochs=3, verbose=1, validation_data=([X_test[:,0], X_test[:,1]], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_id, num_recommendations):\n",
    "    # Obtén los libros que el usuario aún no ha calificado\n",
    "    user_ratings = ratings[ratings['User-ID'] == user_id]\n",
    "    unrated_books = books[~books['ISBN'].isin(user_ratings['ISBN'])]\n",
    "\n",
    "    # Crea un array de entrada para el modelo\n",
    "    user_array = np.array([user_id for _ in range(len(unrated_books))])\n",
    "    book_array = np.array(unrated_books['ISBN'])\n",
    "\n",
    "    # Usa el modelo para predecir las calificaciones\n",
    "    predictions = model.predict([user_array, book_array])\n",
    "\n",
    "    # Añade las predicciones al dataframe de libros no calificados\n",
    "    unrated_books['Predicted-Rating'] = predictions \n",
    "\n",
    "    # Ordena los libros por la calificación predicha\n",
    "    recommended_books = unrated_books.sort_values(by='Predicted-Rating', ascending=False)\n",
    "\n",
    "    # Devuelve solo el título, el autor y la calificación predicha de los libros con las calificaciones más altas\n",
    "    return recommended_books[['Book-Title', 'Book-Author', 'Predicted-Rating']][:num_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomendaciones para un usuario especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8480/8480 [==============================] - 8s 955us/step\n",
      "                                               Book-Title  \\\n",
      "78867                           The Shrinking of Treehorn   \n",
      "184411  Michelin THE GREEN GUIDE Quebec, 4e (THE GREEN...   \n",
      "79431   The Blue Day Book: A Lesson in Cheering Yourse...   \n",
      "31331                              A Kiss for Little Bear   \n",
      "38292                                           The Lorax   \n",
      "3028                                                 Free   \n",
      "16190                                          Falling Up   \n",
      "238677                          Fiction Writer's Handbook   \n",
      "66613                                  M.Y.T.H. Inc. Link   \n",
      "53754             A Baby...Maybe -- How To Hunt a Husband   \n",
      "\n",
      "                         Book-Author  Predicted-Rating  \n",
      "78867           Florence Parry Heide          9.678238  \n",
      "184411  Michelin Travel Publications          9.446127  \n",
      "79431          Bradley Trevor Greive          9.397828  \n",
      "31331         Else Holmelund Minarik          9.312489  \n",
      "38292                      Dr. Seuss          9.297168  \n",
      "3028                    Paul Vincent          9.119722  \n",
      "16190               Shel Silverstein          9.092631  \n",
      "238677                Hallie Burnett          9.017130  \n",
      "66613                  Robert Asprin          8.981538  \n",
      "53754                  Bonnie Tucker          8.959663  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjmom\\AppData\\Local\\Temp\\ipykernel_107016\\2478181155.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unrated_books['Predicted-Rating'] = predictions * 1.3\n"
     ]
    }
   ],
   "source": [
    "print(recommend_books(9, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
